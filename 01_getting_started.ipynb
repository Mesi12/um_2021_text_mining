{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/original/novels/stud.txt\") as fp:\n",
    "    data = fp.read()\n",
    "\n",
    "# clean processed input further\n",
    "# todo add these steps to our preprocessing step\n",
    "data = data.replace(\"\\n\", \" \")\n",
    "data = re.sub(r\" +\", \" \", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo recognize quotes as direct speech\n",
    "# todo sherlock holmes is split into two tokens\n",
    "sent = nltk.tokenize.sent_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.tokenize.word_tokenize(sent[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['``', 'You', 'do', \"n't\", 'know', 'Sherlock', 'Holmes', 'yet', ',', \"''\", 'he', 'said', ';', '``', 'perhaps', 'you', 'would', 'not', 'care', 'for', 'him', 'as', 'a', 'constant', 'companion', '.', \"''\"]\n"
     ]
    }
   ],
   "source": [
    "#print([word for word in words if word not in string.punctuation])\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pos tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('``', '``'),\n",
       " ('You', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('know', 'VB'),\n",
       " ('Sherlock', 'NNP'),\n",
       " ('Holmes', 'NNP'),\n",
       " ('yet', 'RB'),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('he', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " (';', ':'),\n",
       " ('``', '``'),\n",
       " ('perhaps', 'RB'),\n",
       " ('you', 'PRP'),\n",
       " ('would', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('care', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('him', 'PRP'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('constant', 'JJ'),\n",
       " ('companion', 'NN'),\n",
       " ('.', '.'),\n",
       " (\"''\", \"''\")]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## named entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51676 total words contain 6232 unique words.\n"
     ]
    }
   ],
   "source": [
    "# todo stemming\n",
    "# todo lemmatization\n",
    "\n",
    "# rudimentary version\n",
    "wordlist = nltk.word_tokenize(data)\n",
    "unique_words = set(wordlist)\n",
    "\n",
    "print(f\"{len(wordlist)} total words contain {len(unique_words)} unique words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slightly better\n",
    "# https://programminghistorian.org/en/lessons/counting-frequencies\n",
    "\n",
    "wordfreq = [wordlist.count(p) for p in wordlist]\n",
    "freqdict = dict(list(zip(wordlist,wordfreq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = [(freqdict[key], key) for key in freqdict]\n",
    "aux.sort()\n",
    "aux.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2959, ','),\n",
       " (2406, '.'),\n",
       " (2327, 'the'),\n",
       " (1322, 'and'),\n",
       " (1204, 'of'),\n",
       " (1076, 'to'),\n",
       " (963, 'a'),\n",
       " (940, 'I'),\n",
       " (886, '``'),\n",
       " (811, \"''\"),\n",
       " (674, 'in'),\n",
       " (649, 'was'),\n",
       " (630, 'he'),\n",
       " (619, 'that'),\n",
       " (613, 'his'),\n",
       " (471, 'had'),\n",
       " (454, 'it'),\n",
       " (369, 'you'),\n",
       " (315, 'which'),\n",
       " (313, 'with'),\n",
       " (303, 'for'),\n",
       " (300, 'as'),\n",
       " (291, 'is'),\n",
       " (289, 'at'),\n",
       " (278, 'have'),\n",
       " (274, 'my'),\n",
       " (271, 'him'),\n",
       " (249, 'be'),\n",
       " (212, 'me'),\n",
       " (208, 'The'),\n",
       " (208, '?'),\n",
       " (207, 'said'),\n",
       " (195, 'upon'),\n",
       " (193, \"'s\"),\n",
       " (192, 'on'),\n",
       " (179, 'this'),\n",
       " (179, 'not'),\n",
       " (175, 'from'),\n",
       " (173, 'but'),\n",
       " (173, 'He'),\n",
       " (172, 'all'),\n",
       " (169, 'were'),\n",
       " (164, 'her'),\n",
       " (160, 'there'),\n",
       " (155, 'man'),\n",
       " (151, 'by'),\n",
       " (149, 'one'),\n",
       " (147, 'been'),\n",
       " (142, 'we'),\n",
       " (142, 'them'),\n",
       " (142, 'no'),\n",
       " (139, 'so'),\n",
       " (139, 'It'),\n",
       " (135, \"'\"),\n",
       " (133, 'are'),\n",
       " (132, 'they'),\n",
       " (130, 'up'),\n",
       " (128, 'an'),\n",
       " (125, '--'),\n",
       " (119, 'out'),\n",
       " (118, 'would'),\n",
       " (115, 'or'),\n",
       " (112, 'who'),\n",
       " (107, 'do'),\n",
       " (104, ';'),\n",
       " (101, 'some'),\n",
       " (100, 'when'),\n",
       " (99, 'into'),\n",
       " (99, 'You'),\n",
       " (98, 'could'),\n",
       " (98, 'Holmes'),\n",
       " (97, 'There'),\n",
       " (94, 'down'),\n",
       " (91, 'will'),\n",
       " (91, 'their'),\n",
       " (88, \"n't\"),\n",
       " (85, 'over'),\n",
       " (85, '!'),\n",
       " (84, 'your'),\n",
       " (82, 'more'),\n",
       " (80, 'what'),\n",
       " (80, 'little'),\n",
       " (79, 'has'),\n",
       " (76, 'very'),\n",
       " (76, 'time'),\n",
       " (76, 'about'),\n",
       " (75, 'two'),\n",
       " (75, 'she'),\n",
       " (74, 'before'),\n",
       " (73, 'other'),\n",
       " (70, 'any'),\n",
       " (69, 'way'),\n",
       " (67, 'if'),\n",
       " (67, 'face'),\n",
       " (67, 'came'),\n",
       " (65, 'asked'),\n",
       " (64, 'come'),\n",
       " (62, 'Drebber'),\n",
       " (61, 'then'),\n",
       " (61, 'Ferrier')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequent words / tokens\n",
    "# todo need cleaning\n",
    "# todo need stopword removal\n",
    "# todo need merging of words: stemming, lemmatization...\n",
    "aux[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
