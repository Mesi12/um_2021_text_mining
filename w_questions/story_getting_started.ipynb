{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process file: dataset\\processed\\stories\\1_the_adventures_of_sherlock_holmes\\a_case_of_identity.txt\n"
     ]
    }
   ],
   "source": [
    "PATH_DATASET = \"dataset\"\n",
    "PATH_INPUT = \"processed\"\n",
    "PATH_STORIES = \"stories\"\n",
    "PATH_COLLECTION = \"1_the_adventures_of_sherlock_holmes\"\n",
    "FOLDER_PATH = os.path.join(PATH_DATASET,PATH_INPUT,PATH_STORIES,PATH_COLLECTION)\n",
    "f = \"a_case_of_identity.txt\"\n",
    "filepath = os.path.join(FOLDER_PATH,f)\n",
    "\n",
    "if os.path.isfile(filepath) and f.endswith(\".txt\"):\n",
    "    print(f\"Process file: {filepath}\")\n",
    "\n",
    "    with open(filepath, \"r\") as fp:\n",
    "        content = fp.read()\n",
    "else:\n",
    "    print('nem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize content\n",
    "content_sent = nltk.tokenize.sent_tokenize(content)\n",
    "content_word = nltk.tokenize.word_tokenize(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pos tagging\n",
    "tagged_content = nltk.pos_tag(content_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shallow parsing\n",
    "parsed_content = nltk.chunk.ne_chunk(tagged_content)\n",
    "#print(parsed_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PERSON', 'Sherlock Holmes'), ('FACILITY', 'Baker Street'), ('PERSON', 'Holmes'), ('GPE', 'Dundas'), ('PERSON', 'Doctor'), ('GPE', 'Bohemia'), ('ORGANIZATION', 'Irene Adler'), ('GPE', 'Holland'), ('PERSON', 'Marseilles'), ('GPE', 'London'), ('ORGANIZATION', 'Duchess'), ('ORGANIZATION', 'Devonshire'), ('PERSON', 'Miss Mary Sutherland'), ('PERSON', 'Mr. Holmes'), ('PERSON', 'Mr. Hosmer Angel'), ('ORGANIZATION', 'Miss'), ('PERSON', 'Mr. Windibank'), ('PERSON', 'Father'), ('ORGANIZATION', 'Tottenham Court Road'), ('PERSON', 'Mr. Hardy'), ('ORGANIZATION', 'ÂŁ4700'), ('GPE', 'Auckland'), ('GPE', 'New Zealand'), ('ORGANIZATION', 'ÂŁ60'), ('PERSON', 'Watson'), ('PERSON', 'Miss Sutherland'), ('GPE', 'France'), ('ORGANIZATION', 'Hosmer'), ('PERSON', 'Mr. Angel'), ('FACILITY', 'Leadenhall Street'), ('ORGANIZATION', 'Leadenhall Street'), ('ORGANIZATION', 'Leadenhall Street Post'), ('ORGANIZATION', 'Testament'), ('PERSON', 'Mother'), ('GPE', 'Bordeaux'), ('GPE', 'French'), ('GPE', 'England'), ('ORGANIZATION', 'St. Saviour'), ('GPE', 'King'), ('PERSON', 'Cross'), ('ORGANIZATION', 'St. Pancras Hotel'), ('PERSON', 'Hosmer'), ('ORGANIZATION', 'Chronicle'), ('ORGANIZATION', 'Camberwell'), ('ORGANIZATION', 'Westhouse'), ('PERSON', 'Marbank'), ('PERSON', 'Fenchurch Street'), ('GPE', 'Hosmer'), ('GPE', 'Andover'), ('FACILITY', 'The Hague'), ('ORGANIZATION', 'Sherlock Holmes'), ('ORGANIZATION', 'Hosmer Angel'), ('PERSON', 'Albert'), ('GPE', 'Harris'), ('PERSON', 'Balzac'), ('PERSON', 'Angel'), ('ORGANIZATION', 'City'), ('ORGANIZATION', 'Sign'), ('GPE', 'Four'), ('GPE', 'Scarlet'), ('PERSON', 'Baker Street'), ('PERSON', 'Mr. James Windibank'), ('ORGANIZATION', 'Holmes'), ('GPE', 'Windibank'), ('PERSON', 'Hence'), ('PERSON', 'James Windibank'), ('PERSON', 'Windibank'), ('PERSON', 'Jove'), ('GPE', 'Persian'), ('GPE', 'Hafiz'), ('GPE', 'Horace')]\n"
     ]
    }
   ],
   "source": [
    "#find named entities\n",
    "named_entities = [] #would be better to create a set?\n",
    "for chunk in parsed_content:\n",
    "    if hasattr(chunk, 'label'):\n",
    "        entity = chunk.label(), ' '.join(c[0] for c in chunk)\n",
    "        if entity not in named_entities:\n",
    "            named_entities.append(entity)\n",
    "print(named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters:  ['Sherlock Holmes', 'Holmes', 'Doctor', 'Marseilles', 'Miss Mary Sutherland', 'Mr. Holmes', 'Mr. Hosmer Angel', 'Mr. Windibank', 'Father', 'Mr. Hardy', 'Watson', 'Miss Sutherland', 'Mr. Angel', 'Mother', 'Cross', 'Hosmer', 'Marbank', 'Fenchurch Street', 'Albert', 'Balzac', 'Angel', 'Baker Street', 'Mr. James Windibank', 'Hence', 'James Windibank', 'Windibank', 'Jove']\n",
      "geopolitical entities:  ['Dundas', 'Bohemia', 'Holland', 'London', 'Auckland', 'New Zealand', 'France', 'Bordeaux', 'French', 'England', 'King', 'Hosmer', 'Andover', 'Harris', 'Four', 'Scarlet', 'Windibank', 'Persian', 'Hafiz', 'Horace']\n",
      "organizations:  ['Irene Adler', 'Duchess', 'Devonshire', 'Miss', 'Tottenham Court Road', 'ÂŁ4700', 'ÂŁ60', 'Hosmer', 'Leadenhall Street', 'Leadenhall Street Post', 'Testament', 'St. Saviour', 'St. Pancras Hotel', 'Chronicle', 'Camberwell', 'Westhouse', 'Sherlock Holmes', 'Hosmer Angel', 'City', 'Sign', 'Holmes']\n",
      "facilities:  ['Baker Street', 'Leadenhall Street', 'The Hague']\n"
     ]
    }
   ],
   "source": [
    "#group by entity type\n",
    "characters = []\n",
    "facilities = []\n",
    "geopolitical_entities = []\n",
    "organizations = []\n",
    "for e in named_entities:\n",
    "    if e[0] == \"PERSON\":\n",
    "        characters.append(e[1])\n",
    "    elif e[0] == \"FACILITY\":\n",
    "        facilities.append(e[1])\n",
    "    elif e[0] == \"GPE\":\n",
    "        geopolitical_entities.append(e[1])\n",
    "    elif e[0] == \"ORGANIZATION\":\n",
    "        organizations.append(e[1])\n",
    "    else:\n",
    "        print('nem nem')\n",
    "print('Characters: ',characters)\n",
    "print('geopolitical entities: ',geopolitical_entities)\n",
    "print('organizations: ',organizations)\n",
    "print('facilities: ',facilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo find out how to draw tree for sentence - do we need this?\n",
    "#t = nltk.corpus.treebank.parsed_sents('wsj_0001.mrg')[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
