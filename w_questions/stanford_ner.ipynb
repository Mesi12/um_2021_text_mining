{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the Stanford NER tagger\n",
    "st = nltk.tag.StanfordNERTagger('C:/Program Files/stanford-ner-4.2.0/stanford-ner-2020-11-17/classifiers/english.muc.7class.distsim.crf.ser.gz', 'C:/Program Files/stanford-ner-4.2.0/stanford-ner-2020-11-17/stanford-ner.jar', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "PATH_DATASET = \"dataset\"\n",
    "PATH_INPUT = \"processed\"\n",
    "PATH_STORIES = \"stories\"\n",
    "\n",
    "PATH_COLLECTION = \"3_the_return_of_sherlock_holmes\"\n",
    "FOLDER_PATH = os.path.join('..',PATH_DATASET,PATH_INPUT,PATH_STORIES,PATH_COLLECTION)\n",
    "f = \"the_adventure_of_black_peter.txt\"\n",
    "filepath = os.path.join(FOLDER_PATH,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process file: ..\\dataset\\processed\\stories\\3_the_return_of_sherlock_holmes\\the_adventure_of_black_peter.txt\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(filepath) and f.endswith(\".txt\") :\n",
    "    print(f\"Process file: {filepath}\")\n",
    "\n",
    "    with open(filepath, \"r\") as fp:\n",
    "        content = fp.read()\n",
    "            \n",
    "tokenized_content = nltk.tokenize.word_tokenize(content)\n",
    "tagged_content = st.tag(tokenized_content)\n",
    "\n",
    "pos_tags = nltk.pos_tag(tokenized_content)\n",
    "\n",
    "#print(tagged_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last\n",
      "night\n",
      "night\n",
      "morning\n",
      "night\n",
      "night\n",
      "last\n",
      "night\n",
      "last\n",
      "night\n"
     ]
    }
   ],
   "source": [
    "for t in tagged_content:\n",
    "    if t[1] == \"TIME\":\n",
    "        print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters: ['Wilson', 'Peter Carey', 'Sherlock Holmes', 'Holmes', 'Holmes', 'Watson', 'Allardyce', 'Hopkins', 'Stanley Hopkins', 'Holmes', 'Hopkins', 'Holmes', 'Watson', 'Stanley Hopkins', 'Peter Carey', 'Woodman', 'Holmes', 'Peter Carey', 'Peter', 'Holmes', 'Peter', 'Holmes', 'Slater', 'Peter Carey', 'Tuesday Peter Carey', 'Holmes', 'Hopkins', 'Holmes', 'Peter Carey', 'Holmes', 'Holmes', 'Stanley Hopkins', 'Hopkins', 'Holmes', 'Holmes', 'Stanley Hopkins', 'Holmes', 'Sherlock Holmes', 'Holmes', 'Carey', 'Holmes', 'Stanley Hopkins', 'Watson', 'Hopkins', 'Stanley Hopkins', 'Peter Carey', 'Stanley Hopkins', 'Holmes', 'Hopkins', 'Watson', 'Hopkins', 'Hopkins', 'Holmes', 'Hopkins', 'Stanley Hopkins', 'Peter Carey', 'Hopkins', 'John Hopley Neligan', 'Holmes', 'Hopkins', 'Dawson', 'Hopkins', 'Holmes', 'Neligan', 'Peter Carey', 'Dawson', 'Peter Carey', 'Peter Carey', 'Peter Carey', 'Hopkins', 'Hopkins', 'Hopkins', 'Holmes', 'Watson', 'Holmes', 'Watson', 'Stanley Hopkins', 'Watson', 'Stanley Hopkins', 'Sherlock Holmes', 'Watson', 'Stanley Hopkins', 'Hudson', 'Holmes', 'Holmes', 'Woodman', 'Peter Carey', 'Peter Carey', 'Neligan', 'Holmes', 'Hopkins', 'Watson', 'Black Peter', 'Hopkins', 'Holmes', 'Neligan', 'Holmes', 'Holmes', 'Holmes', 'Watson', 'Hudson', 'Holmes', 'James Lancaster', 'Hugh Pattins', 'Holmes', 'Patrick Cairns', 'Holmes', 'Holmes', 'Hopkins', 'Hopkins', 'Sherlock Holmes', 'Stanley Hopkins', 'Holmes', 'Holmes', 'Patrick Cairns', 'Peter Carey', 'Peter Carey', 'Peter Carey', 'Holmes', 'Black Peter', 'Peter', 'Holmes', 'Peter Carey', 'Peter Carey', 'Peter Carey', 'Tunbridge Wells', 'Peter', 'Peter', 'Holmes', 'Hopkins', 'Patrick Cairns', 'Holmes', 'Hopkins', 'Peter Carey', 'Patrick Cairns', 'Hopkins', 'Holmes', 'Peter Carey', 'Hopkins', 'Watson']\n",
      "locations: ['London', 'London', 'London', 'Sussex', 'Costa Rica', 'San Paulo', 'South America', 'Britain', 'Norfolk', 'Cornwall', 'Norway', 'London', 'Norway', 'Brixton', 'London', 'Carey', 'Lancaster', 'Shetland', 'Scotland', 'London', 'London', 'London', 'Dundee', 'London', 'Norway']\n",
      "dates / times: ['first week of July', 'last night', '1883', '1884', 'night', 'Monday', 'Wednesday', 'morning', '1883', 'night', 'night', 'last night', 'August , 1883', 'last night', 'August', '1883']\n"
     ]
    }
   ],
   "source": [
    "zipped = [[name, pos, tp[1]] for (name,pos), tp in zip(pos_tags, tagged_content)]\n",
    "tree = IOB_to_tree(zipped)\n",
    "\n",
    "person = []\n",
    "location = []\n",
    "time = []\n",
    "\n",
    "for chunk in tree:\n",
    "    if hasattr(chunk, 'label'):\n",
    "        entity = \" \".join(part[0] for part in chunk.leaves())\n",
    "        if chunk.label() == \"PERSON\":\n",
    "            person.append(entity)\n",
    "        elif chunk.label() == \"LOCATION\":\n",
    "            location.append(entity)\n",
    "        elif (chunk.label() == \"DATE\") or (chunk.label() == \"TIME\"):\n",
    "            time.append(entity)\n",
    "        #print(chunk.label(), entity)\n",
    "print(f\"characters: {person}\")  \n",
    "print(f\"locations: {location}\")\n",
    "print(f\"dates / times: {time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Andrew/NNP)\n",
      "  is/VBZ\n",
      "  part/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION Republican/NNP Party/NNP)\n",
      "  in/IN\n",
      "  (LOCATION Dallas/NNP))\n"
     ]
    }
   ],
   "source": [
    "def IOB_to_tree(iob_tagged):\n",
    "    \"\"\"\n",
    "    Say input output, what the function does.\n",
    "    \"\"\"\n",
    "    root = nltk.Tree('S', [])\n",
    "    for token in iob_tagged:\n",
    "        if token[2] == 'O':\n",
    "            root.append((token[0], token[1]))\n",
    "        else:\n",
    "            try:\n",
    "                if root[-1].label() == token[2]:\n",
    "                    root[-1].append((token[0], token[1]))\n",
    "                else:\n",
    "                    root.append(Tree(token[2], [(token[0], token[1])]))\n",
    "            except:\n",
    "                root.append(Tree(token[2], [(token[0], token[1])]))\n",
    "    return root\n",
    "\n",
    "#reference: https://stackoverflow.com/questions/27629130/chunking-stanford-named-entity-recognizer-ner-outputs-from-nltk-format - how to cite it??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"Arthur Baba and Mesi Baba is from New York and he likes to eat at Mama's Little Bakery in Autumn.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Arthur', 'NNP', 'PERSON'],\n",
       " ['Baba', 'NNP', 'PERSON'],\n",
       " ['and', 'CC', 'O'],\n",
       " ['Mesi', 'NNP', 'PERSON'],\n",
       " ['Baba', 'NNP', 'PERSON'],\n",
       " ['is', 'VBZ', 'O'],\n",
       " ['from', 'IN', 'O'],\n",
       " ['New', 'NNP', 'LOCATION'],\n",
       " ['York', 'NNP', 'LOCATION'],\n",
       " ['and', 'CC', 'O'],\n",
       " ['he', 'PRP', 'O'],\n",
       " ['likes', 'VBZ', 'O'],\n",
       " ['to', 'TO', 'O'],\n",
       " ['eat', 'VB', 'O'],\n",
       " ['at', 'IN', 'O'],\n",
       " ['Mama', 'NNP', 'ORGANIZATION'],\n",
       " [\"'s\", 'POS', 'ORGANIZATION'],\n",
       " ['Little', 'JJ', 'ORGANIZATION'],\n",
       " ['Bakery', 'NNP', 'ORGANIZATION'],\n",
       " ['in', 'IN', 'O'],\n",
       " ['Autumn', 'NNP', 'DATE'],\n",
       " ['.', '.', 'O']]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = nltk.tokenize.word_tokenize(sent)\n",
    "pos = nltk.pos_tag(tok)\n",
    "ner = st.tag(tok)\n",
    "new = [[name, pos, tp[1]] for (name,pos), tp in zip(pos, ner)]\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Arthur/NNP Baba/NNP)\n",
      "  and/CC\n",
      "  (PERSON Mesi/NNP Baba/NNP)\n",
      "  is/VBZ\n",
      "  from/IN\n",
      "  (LOCATION New/NNP York/NNP)\n",
      "  and/CC\n",
      "  he/PRP\n",
      "  likes/VBZ\n",
      "  to/TO\n",
      "  eat/VB\n",
      "  at/IN\n",
      "  (ORGANIZATION Mama/NNP 's/POS Little/JJ Bakery/NNP)\n",
      "  in/IN\n",
      "  (DATE Autumn/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "tr = IOB_to_tree(new)\n",
    "print(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters: ['Arthur Baba', 'Mesi Baba']\n",
      "locations: ['New York']\n",
      "dates / times: ['Autumn']\n"
     ]
    }
   ],
   "source": [
    "person = []\n",
    "location = []\n",
    "time = []\n",
    "\n",
    "for chunk in tr:\n",
    "    if hasattr(chunk, 'label'):\n",
    "        entity = \" \".join(part[0] for part in chunk.leaves())\n",
    "        if chunk.label() == \"PERSON\":\n",
    "            person.append(entity)\n",
    "        elif chunk.label() == \"LOCATION\":\n",
    "            location.append(entity)\n",
    "        elif (chunk.label() == \"DATE\") or (chunk.label() == \"TIME\"):\n",
    "            time.append(entity)\n",
    "        #print(chunk.label(), entity)\n",
    "print(f\"characters: {person}\")  \n",
    "print(f\"locations: {location}\")\n",
    "print(f\"dates / times: {time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
