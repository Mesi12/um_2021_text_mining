{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford CoreNLP Server usage\n",
    "\n",
    "Running Stanford CoreNLP https://stanfordnlp.github.io/CoreNLP/index.html  \n",
    "Using nltk https://github.com/nltk/nltk/wiki/Stanford-CoreNLP-API-in-NLTK\n",
    "\n",
    "1. Download latest version of CoreNLP from above website (here 4.2.2)\n",
    "2. Start server as on github link\n",
    "3. Use nltk as shown below\n",
    "\n",
    "Java server start\n",
    "```bash\n",
    "java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer \\\n",
    "-preload tokenize,ssplit,pos,lemma,ner,parse,depparse \\\n",
    "-status_port 9000 -port 9000 -timeout 15000 & \n",
    "```\n",
    "\n",
    "Stopping server:\n",
    "\n",
    "- on mac: find and kill -> `ps aux | grep StanfordCoreNLPServer`\n",
    "- on windows: ctrl+c (worked somehow)\n",
    "- https://stackoverflow.com/questions/55896197/an-elegant-way-to-shut-down-the-stanford-corenlp-server-on-macos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import CoreNLPParser\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "\n",
    "# Lexical Parser\n",
    "parser = CoreNLPParser(url='http://localhost:9000')\n",
    "# POS tagger\n",
    "pos_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='pos')\n",
    "# NER Tagger\n",
    "ner_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='ner')\n",
    "# Neural Dependency Parser\n",
    "dep_parser = CoreNLPDependencyParser(url='http://localhost:9000')\n",
    "\n",
    "# sentence as example\n",
    "sentence = \"Alice was a beautiful girl, because she didn't do homework.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alice',\n",
       " 'was',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " 'girl',\n",
       " ',',\n",
       " 'because',\n",
       " 'she',\n",
       " 'did',\n",
       " \"n't\",\n",
       " 'do',\n",
       " 'homework',\n",
       " '.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = list(parser.tokenize(sentence))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tagger (part-of-speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Alice', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('girl', 'NN'),\n",
       " (',', ','),\n",
       " ('because', 'IN'),\n",
       " ('she', 'PRP'),\n",
       " ('did', 'VBD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('do', 'VB'),\n",
       " ('homework', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags = list(pos_tagger.tag(tokens))\n",
    "pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER tagger (named entity recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Alice', 'PERSON'),\n",
       " ('was', 'O'),\n",
       " ('a', 'O'),\n",
       " ('beautiful', 'O'),\n",
       " ('girl', 'O'),\n",
       " (',', 'O'),\n",
       " ('because', 'O'),\n",
       " ('she', 'O'),\n",
       " ('did', 'O'),\n",
       " (\"n't\", 'O'),\n",
       " ('do', 'O'),\n",
       " ('homework', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tags = list(ner_tagger.tag(tokens))\n",
    "ner_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(('girl', 'NN'), 'nsubj', ('Alice', 'NNP')),\n",
       "  (('girl', 'NN'), 'cop', ('was', 'VBD')),\n",
       "  (('girl', 'NN'), 'det', ('a', 'DT')),\n",
       "  (('girl', 'NN'), 'amod', ('beautiful', 'JJ')),\n",
       "  (('girl', 'NN'), 'punct', (',', ',')),\n",
       "  (('girl', 'NN'), 'advcl', ('do', 'VB')),\n",
       "  (('do', 'VB'), 'mark', ('because', 'IN')),\n",
       "  (('do', 'VB'), 'nsubj', ('she', 'PRP')),\n",
       "  (('do', 'VB'), 'aux', ('did', 'VBD')),\n",
       "  (('do', 'VB'), 'advmod', (\"n't\", 'RB')),\n",
       "  (('do', 'VB'), 'obj', ('homework', 'NN')),\n",
       "  (('girl', 'NN'), 'punct', ('.', '.'))]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parses = dep_parser.parse(tokens)\n",
    "[[(governor, dep, dependent) for governor, dep, dependent in parse.triples()] for parse in parses]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General parsing & drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('ROOT', [Tree('S', [Tree('NP', [Tree('NNP', ['Alice'])]), Tree('VP', [Tree('VBD', ['was']), Tree('NP', [Tree('DT', ['a']), Tree('JJ', ['beautiful']), Tree('NN', ['girl'])]), Tree(',', [',']), Tree('SBAR', [Tree('IN', ['because']), Tree('S', [Tree('NP', [Tree('PRP', ['she'])]), Tree('VP', [Tree('VBD', ['did']), Tree('RB', [\"n't\"]), Tree('VP', [Tree('VB', ['do']), Tree('NP', [Tree('NN', ['homework'])])])])])])]), Tree('.', ['.'])])])]\n",
      "                                   ROOT                                   \n",
      "                                    |                                      \n",
      "                                    S                                     \n",
      "   _________________________________|___________________________________   \n",
      "  |                                 VP                                  | \n",
      "  |     ____________________________|_____                              |  \n",
      "  |    |          |           |          SBAR                           | \n",
      "  |    |          |           |      _____|____                         |  \n",
      "  |    |          |           |     |          S                        | \n",
      "  |    |          |           |     |      ____|___                     |  \n",
      "  |    |          |           |     |     |        VP                   | \n",
      "  |    |          |           |     |     |     ___|_______             |  \n",
      "  |    |          |           |     |     |    |   |       VP           | \n",
      "  |    |          |           |     |     |    |   |    ___|_____       |  \n",
      "  NP   |          NP          |     |     NP   |   |   |         NP     | \n",
      "  |    |    ______|______     |     |     |    |   |   |         |      |  \n",
      " NNP  VBD  DT     JJ     NN   ,     IN   PRP  VBD  RB  VB        NN     . \n",
      "  |    |   |      |      |    |     |     |    |   |   |         |      |  \n",
      "Alice was  a  beautiful girl  ,  because she  did n't  do     homework  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotated_tree = list(parser.raw_parse(sentence))\n",
    "print(annotated_tree)\n",
    "annotated_tree[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Own functions\n",
    "\n",
    "Reason: Not all CoreNLP server features are implemented in nltk (3.6.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CoreNLPHelper import CoreNLPHelper\n",
    "nlp_helper = CoreNLPHelper(core_nlp_server_url='http://localhost:9000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### active/ passive identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "active_sentence = \"Researchers found a stone so I am happy.\"\n",
    "passive_sentence = \"A stone was found by researchers.\"\n",
    "\n",
    "print(nlp_helper.is_sentence_passive(active_sentence))\n",
    "print(nlp_helper.is_sentence_passive(passive_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment value is: 3\n",
      "Sentiment distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01376237703559,\n",
       " 0.06090227273432,\n",
       " 0.13703558107487,\n",
       " 0.50267238875958,\n",
       " 0.28562738039563]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Sentiment value is: {nlp_helper.get_sentiment_value(sentence)}\")\n",
    "print(\"Sentiment distribution:\")\n",
    "nlp_helper.get_sentiment_distribution(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coreference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2': [{'id': 0,\n",
       "   'text': 'Alice',\n",
       "   'type': 'PROPER',\n",
       "   'number': 'SINGULAR',\n",
       "   'gender': 'FEMALE',\n",
       "   'animacy': 'ANIMATE',\n",
       "   'startIndex': 1,\n",
       "   'endIndex': 2,\n",
       "   'headIndex': 1,\n",
       "   'sentNum': 1,\n",
       "   'position': [1, 1],\n",
       "   'isRepresentativeMention': True},\n",
       "  {'id': 2,\n",
       "   'text': 'she',\n",
       "   'type': 'PRONOMINAL',\n",
       "   'number': 'SINGULAR',\n",
       "   'gender': 'FEMALE',\n",
       "   'animacy': 'ANIMATE',\n",
       "   'startIndex': 8,\n",
       "   'endIndex': 9,\n",
       "   'headIndex': 8,\n",
       "   'sentNum': 1,\n",
       "   'position': [1, 3],\n",
       "   'isRepresentativeMention': False}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corefs = nlp_helper.get_coreferences(sentence)\n",
    "corefs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
